{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024183b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9596d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a79f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train_div = x_train / 255\n",
    "x_test_div = x_test / 255\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bed90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_(tf.Module):\n",
    "    def __init__(self, kernel=(3, 3), filters=1, strides=(1, 1), padding='VALID', activation='relu'):\n",
    "        super().__init__()\n",
    "        self.kernel = kernel\n",
    "        self.filters = filters\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.fl_init = False\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            self.w = tf.random.truncated_normal(shape=(*self.kernel, x.shape[-1], self.filters),\n",
    "                                                mean=0.0, stddev=0.5, dtype=tf.float32, name='w')\n",
    "            self.b = tf.zeros(shape=(self.filters,), dtype=tf.float32, name='b')\n",
    "            \n",
    "            self.w = tf.Variable(self.w)\n",
    "            self.b = tf.Variable(self.b)\n",
    "            self.fl_init = True\n",
    "        \n",
    "        y = tf.nn.conv2d(x, self.w, strides=(1, *self.strides, 1), padding=self.padding) + self.b\n",
    "        \n",
    "        if self.activation == 'relu':\n",
    "            return tf.nn.relu(y)\n",
    "        elif self.activation == 'softmax':\n",
    "            return tf.nn.softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5049b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_(tf.Module):\n",
    "    def __init__(self, outputs, activate=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.outputs = outputs\n",
    "        self.activate = activate\n",
    "        self.fl_init = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, dtype=tf.float32, name=\"w\")\n",
    "            self.b = tf.zeros([self.outputs], dtype=tf.float32, name=\"b\")\n",
    "\n",
    "            self.w = tf.Variable(self.w)\n",
    "            self.b = tf.Variable(self.b)\n",
    "\n",
    "            self.fl_init = True\n",
    "\n",
    "        y = x @ self.w + self.b\n",
    "\n",
    "        if self.activate == \"relu\":\n",
    "            return tf.nn.relu(y)\n",
    "        elif self.activate == \"softmax\":\n",
    "            return tf.nn.softmax(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2f707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten_(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def __call__(self, inputs):\n",
    "        return tf.reshape(inputs, shape=(inputs.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2aafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling_(tf.Module):\n",
    "    def __init__(self, pool_size=(2, 2), strides=(1, 1), padding='VALID'):\n",
    "        super().__init__()\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    def __call__(self, inputs):\n",
    "        y = tf.nn.max_pool2d(input=inputs, \n",
    "                             ksize=self.pool_size, \n",
    "                             strides=self.strides, \n",
    "                             padding=self.padding)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7a5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_(tf.keras.Model):\n",
    "    def __init__(self, name='T-Rex'):\n",
    "        super().__init__(name=name)\n",
    "        self.layer1 = Conv2D_((3, 3), 32, (1, 1), 'SAME')\n",
    "        self.layer2 = Conv2D_((3, 3), 32, (1, 1), 'SAME')\n",
    "        self.layer3 = MaxPooling_(pool_size=(2, 2), strides=(1, 1), padding='SAME')\n",
    "        self.layer4 = Conv2D_((3, 3), 64, (1, 1), 'SAME')\n",
    "        self.layer5 = Conv2D_((3, 3), 64, (1, 1), 'SAME')\n",
    "        self.layer6 = MaxPooling_(pool_size=(2, 2), strides=(1, 1), padding='SAME')\n",
    "        self.layer7 = Flatten_()\n",
    "        self.layer8 = Dense_(10, 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        inputs = tf.expand_dims(inputs, axis=-1)\n",
    "        y = self.layer1(inputs)\n",
    "        y = self.layer2(y)\n",
    "        y = self.layer3(y)\n",
    "        y = self.layer4(y)\n",
    "        y = self.layer5(y)\n",
    "        y = self.layer6(y)\n",
    "        y = self.layer7(y)\n",
    "        y = self.layer8(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328e0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "TOTAL = x_train_div.shape[0]\n",
    "BATCH_SIZE = 32\n",
    "BATCH_EPOCHS = TOTAL // BATCH_SIZE\n",
    "\n",
    "batch_dataset = tf.data.Dataset.from_tensor_slices((x_train_div, y_train_cat))\n",
    "batch_dataset = batch_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "opt = Adam(learning_rate=0.0018)\n",
    "cross_entropy = lambda y_true, y_pred: tf.reduce_mean(tf.losses.categorical_crossentropy(y_true, y_pred))\n",
    "\n",
    "model = Model_()\n",
    "\n",
    "@tf.function\n",
    "def f_loss(x_batch, y_batch):\n",
    "    with tf.GradientTape(watch_accessed_variables=True, persistent=False) as tape:\n",
    "        loss = cross_entropy(y_batch, model(x_batch))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a8cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1| epoch_loss: 2048.406005859375, epoch_categorical_accuracy: 0.96875;                               \n",
      "Epoch: 2| epoch_loss: 1289.505615234375, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 3| epoch_loss: 906.9053344726562, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 4| epoch_loss: 597.3038330078125, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 5| epoch_loss: 408.99932861328125, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 6| epoch_loss: 309.1285400390625, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 7| epoch_loss: 255.37704467773438, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 8| epoch_loss: 179.13046264648438, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 9| epoch_loss: 164.32870483398438, epoch_categorical_accuracy: 1.0;                               \n",
      "Epoch: 10| epoch_loss: 124.21366119384766, epoch_categorical_accuracy: 1.0;                               \n"
     ]
    }
   ],
   "source": [
    "for n in range(EPOCHS):\n",
    "    loss = 0\n",
    "    cat_accuracy = 0\n",
    "    passed = 0\n",
    "    for x_batch, y_batch in batch_dataset:\n",
    "        loss += f_loss(x_batch, y_batch)\n",
    "        ac = tf.keras.metrics.CategoricalAccuracy()\n",
    "        ac.update_state(y_batch, model(x_batch))\n",
    "        cat_accuracy = ac.result().numpy()\n",
    "        passed += 1\n",
    "        print(f'Epoch: {n+1} |{passed}/{BATCH_EPOCHS}| loss: {loss}, bacategorical_accuracy: {cat_accuracy}',\\\n",
    "              end='\\r')\n",
    "    print(f'Epoch: {n+1}| epoch_loss: {loss}, epoch_categorical_accuracy: {cat_accuracy};                               ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3180b4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_test_loss: 0.13927502930164337, test_categorical_accuracy: 0.9818000197410583\n"
     ]
    }
   ],
   "source": [
    "ac = tf.keras.metrics.CategoricalAccuracy()\n",
    "ac.update_state(y_test_cat, model(x_test_div))\n",
    "test_categorical_accuracy = ac.result().numpy()\n",
    "\n",
    "mean_test_loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_test_cat, model(x_test_div)))\n",
    "\n",
    "print(f'Mean_test_loss: {mean_test_loss}, test_categorical_accuracy: {test_categorical_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
